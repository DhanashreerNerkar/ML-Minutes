<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XGBoost for Ranking - Complete Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            line-height: 1.6;
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 25px;
            padding: 50px;
            backdrop-filter: blur(20px);
        }
        
        .main-title {
            font-size: 3.5em;
            font-weight: bold;
            margin-bottom: 20px;
            background: linear-gradient(45deg, #ffd700, #ff6b6b, #4ecdc4);
            background-size: 300% 300%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: gradient 4s ease infinite;
        }
        
        .subtitle {
            font-size: 1.4em;
            opacity: 0.9;
        }
        
        .nav-tabs {
            display: flex;
            justify-content: center;
            margin-bottom: 40px;
            flex-wrap: wrap;
            gap: 12px;
        }
        
        .tab-btn {
            background: rgba(255, 255, 255, 0.2);
            border: none;
            color: white;
            padding: 12px 20px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s ease;
        }
        
        .tab-btn:hover, .tab-btn.active {
            background: linear-gradient(45deg, #ffd700, #ff9ff3);
            transform: translateY(-2px);
        }
        
        .content-section {
            display: none;
            animation: fadeIn 0.5s ease;
        }
        
        .content-section.active {
            display: block;
        }
        
        .concept-card {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(15px);
            margin: 25px 0;
            border-left: 5px solid #ffd700;
        }
        
        .card-title {
            font-size: 1.8em;
            font-weight: bold;
            margin-bottom: 20px;
            color: #ffd700;
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }
        
        .feature-card {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 15px;
            padding: 25px;
            border-left: 5px solid;
            transition: all 0.3s ease;
        }
        
        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.3);
        }
        
        .education-card { border-left-color: #4ecdc4; }
        .projects-card { border-left-color: #ffd700; }
        .skills-card { border-left-color: #ff6b6b; }
        .experience-card { border-left-color: #a8e6cf; }
        
        .feature-title {
            font-size: 1.4em;
            font-weight: bold;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .weight-badge {
            background: linear-gradient(45deg, #ff6b6b, #ffd700);
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 0.8em;
            margin-left: auto;
        }
        
        .workflow-section {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 35px;
            margin: 35px 0;
        }
        
        .workflow-title {
            font-size: 2em;
            font-weight: bold;
            text-align: center;
            margin-bottom: 30px;
            color: #ffd700;
        }
        
        .workflow-steps {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 25px 0;
        }
        
        .workflow-step {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 15px;
            padding: 20px;
            text-align: center;
            position: relative;
        }
        
        .step-number {
            background: #ffd700;
            color: #333;
            width: 35px;
            height: 35px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin: 0 auto 15px;
        }
        
        .step-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
            color: #4ecdc4;
        }
        
        .code-example {
            background: rgba(0, 0, 0, 0.7);
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        
        .code-title {
            color: #4ecdc4;
            font-size: 1.2em;
            margin-bottom: 15px;
            font-weight: bold;
        }
        
        .code-line {
            margin: 8px 0;
            font-size: 0.9em;
        }
        
        .keyword { color: #ff6b6b; }
        .string { color: #ffd700; }
        .number { color: #4ecdc4; }
        .comment { color: #a8e6cf; font-style: italic; }
        
        .xgboost-architecture {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            margin: 30px 0;
        }
        
        .architecture-title {
            font-size: 1.8em;
            font-weight: bold;
            text-align: center;
            margin-bottom: 25px;
            color: #ffd700;
        }
        
        .tree-visualization {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 30px 0;
            flex-wrap: wrap;
            gap: 20px;
        }
        
        .tree-group {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 15px;
        }
        
        .tree-box {
            width: 60px;
            height: 60px;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            transition: all 0.3s ease;
            background: linear-gradient(45deg, #667eea, #764ba2);
        }
        
        .tree-box:hover {
            transform: scale(1.1);
        }
        
        .arrow {
            font-size: 2em;
            color: #ffd700;
            margin: 0 15px;
        }
        
        .bagging-features {
            background: rgba(78, 205, 196, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            border-left: 4px solid #4ecdc4;
        }
        
        .boosting-features {
            background: rgba(255, 215, 0, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            border-left: 4px solid #ffd700;
        }
        
        .results-table {
            background: white;
            color: #333;
            border-radius: 15px;
            overflow: hidden;
            margin: 25px 0;
        }
        
        .table-header {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 15px;
            font-weight: bold;
            text-align: center;
        }
        
        .table-row {
            display: grid;
            grid-template-columns: 2fr 1fr 1fr 1fr 1fr 1fr;
            border-bottom: 1px solid #eee;
        }
        
        .table-cell {
            padding: 12px;
            border-right: 1px solid #eee;
            text-align: center;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .table-cell:last-child {
            border-right: none;
        }
        
        .table-row:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        @media (max-width: 768px) {
            .feature-grid {
                grid-template-columns: 1fr;
            }
            
            .main-title {
                font-size: 2.5em;
            }
            
            .table-row {
                grid-template-columns: 1fr;
                text-align: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="main-title">XGBoost Deep Dive</div>
            <div class="subtitle">How XGBoost Combines Bagging + Boosting for Your Ranking Model</div>
        </div>
        
        <div class="nav-tabs">
            <button class="tab-btn active" onclick="showSection('xgboost-nature')">🤖 XGBoost Nature</button>
            <button class="tab-btn" onclick="showSection('your-usecase')">💼 Your Use Case</button>
            <button class="tab-btn" onclick="showSection('implementation')">💻 Implementation</button>
            <button class="tab-btn" onclick="showSection('optimization')">🎯 Optimization</button>
        </div>

        <!-- XGBoost Nature -->
        <div id="xgboost-nature" class="content-section active">
            <div class="concept-card">
                <div class="card-title">
                    <span>🎯</span>
                    XGBoost: The Best of Both Worlds
                </div>
                <div style="font-size: 1.2em; line-height: 1.8; margin-bottom: 25px;">
                    <strong>XGBoost is PRIMARILY boosting, but cleverly incorporates bagging techniques!</strong>
                </div>
                
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin: 30px 0;">
                    <div class="boosting-features">
                        <h3 style="color: #ffd700; margin-bottom: 15px;">🚀 Boosting Components (Primary)</h3>
                        <div style="font-size: 1.05em;">
                            ✅ <strong>Sequential tree building</strong> - each tree corrects previous errors<br>
                            ✅ <strong>Gradient-based optimization</strong> - minimizes loss function<br>
                            ✅ <strong>Residual learning</strong> - new trees predict what's left to learn<br>
                            ✅ <strong>Weighted combination</strong> - trees vote with different importance<br>
                            ✅ <strong>Learning rate</strong> - controls contribution of each tree
                        </div>
                    </div>
                    
                    <div class="bagging-features">
                        <h3 style="color: #4ecdc4; margin-bottom: 15px;">🎒 Bagging Components (Secondary)</h3>
                        <div style="font-size: 1.05em;">
                            ✅ <strong>Row subsampling</strong> - each tree sees different data rows<br>
                            ✅ <strong>Column subsampling</strong> - each tree uses random features<br>
                            ✅ <strong>Bootstrap-like sampling</strong> - adds randomness and diversity<br>
                            ✅ <strong>Parallel tree construction</strong> - can build multiple trees simultaneously<br>
                            ✅ <strong>Regularization</strong> - prevents overfitting like bagging does
                        </div>
                    </div>
                </div>
            </div>

            <div class="xgboost-architecture">
                <div class="architecture-title">🏗️ XGBoost Architecture: How It Combines Both</div>
                
                <div class="tree-visualization">
                    <div class="tree-group">
                        <div style="font-size: 1em; margin-bottom: 10px;">Iteration 1</div>
                        <div class="tree-box">T1</div>
                        <div style="font-size: 0.8em; margin-top: 5px;">Subsample: 80% rows<br>Features: 80% cols</div>
                    </div>
                    
                    <div class="arrow">→</div>
                    
                    <div class="tree-group">
                        <div style="font-size: 1em; margin-bottom: 10px;">Iteration 2</div>
                        <div class="tree-box">T2</div>
                        <div style="font-size: 0.8em; margin-top: 5px;">Focus on T1's errors<br>New random sample</div>
                    </div>
                    
                    <div class="arrow">→</div>
                    
                    <div class="tree-group">
                        <div style="font-size: 1em; margin-bottom: 10px;">Iteration N</div>
                        <div class="tree-box">TN</div>
                        <div style="font-size: 0.8em; margin-top: 5px;">Fix remaining errors<br>Another random sample</div>
                    </div>
                    
                    <div class="arrow">→</div>
                    
                    <div class="tree-group">
                        <div style="font-size: 1em; margin-bottom: 10px;">Final Model</div>
                        <div style="width: 80px; height: 80px; border-radius: 15px; background: linear-gradient(45deg, #ff6b6b, #ffd700); display: flex; align-items: center; justify-content: center; font-size: 1.2em; font-weight: bold;">∑</div>
                        <div style="font-size: 0.8em; margin-top: 5px;">Weighted sum<br>of all trees</div>
                    </div>
                </div>
                
                <div style="background: rgba(255,255,255,0.1); padding: 25px; border-radius: 15px; margin: 25px 0;">
                    <h4 style="color: #ffd700; margin-bottom: 15px; text-align: center;">🔄 The Hybrid Process</h4>
                    <div style="font-size: 1.1em; line-height: 1.7;">
                        <strong>1. Boosting Foundation:</strong> Each tree learns from previous tree's mistakes (sequential)<br>
                        <strong>2. Bagging Enhancement:</strong> Each tree is trained on random subset of data and features<br>
                        <strong>3. Result:</strong> Sequential error correction + Diverse tree perspectives = Superior performance!
                    </div>
                </div>
            </div>

            <div class="concept-card">
                <div class="card-title">
                    <span>⚡</span>
                    Why XGBoost Dominates Structured Data
                </div>
                <div style="font-size: 1.1em; line-height: 1.8;">
                    <p style="margin-bottom: 20px;">
                        <strong>Your ranking problem is PERFECT for XGBoost!</strong> Here's why:
                    </p>
                    
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 25px 0;">
                        <div style="background: rgba(78,205,196,0.2); padding: 20px; border-radius: 12px;">
                            <strong>🎯 Structured Features</strong><br>
                            Your features (education, projects, skills, publications) are structured/tabular - XGBoost's sweet spot!
                        </div>
                        
                        <div style="background: rgba(255,215,0,0.2); padding: 20px; border-radius: 12px;">
                            <strong>📊 Ranking Task</strong><br>
                            XGBoost excels at ranking problems with its built-in ranking objective functions!
                        </div>
                        
                        <div style="background: rgba(255,107,107,0.2); padding: 20px; border-radius: 12px;">
                            <strong>⚖️ Feature Importance</strong><br>
                            Your weighted scoring (50% education, 40% projects, 10% skills) aligns perfectly with XGBoost's feature importance!
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Your Use Case -->
        <div id="your-usecase" class="content-section">
            <div style="text-align: center; margin-bottom: 30px;">
                <h2 style="color: #ffd700; font-size: 2.5em; margin-bottom: 15px;">💼 Your Ranking Model Deep Dive</h2>
                <div style="font-size: 1.2em; opacity: 0.9;">Semantic Scoring + XGBoost for Candidate Ranking</div>
            </div>

            <div class="feature-grid">
                <div class="feature-card education-card">
                    <div class="feature-title">
                        <span>🎓</span>
                        Education Score
                        <span class="weight-badge">50% Weight</span>
                    </div>
                    <div>
                        <strong>Semantic Comparison:</strong><br>
                        • Candidate's education vs job qualifications<br>
                        • Degree level, field of study, institution ranking<br>
                        • Text similarity between degrees and requirements<br><br>
                        <strong>Example:</strong><br>
                        Job requires: "Master's in Computer Science"<br>
                        Candidate has: "MS in Software Engineering"<br>
                        Semantic Score: 0.85 (high similarity)
                    </div>
                </div>

                <div class="feature-card projects-card">
                    <div class="feature-title">
                        <span>🚀</span>
                        Projects & Publications
                        <span class="weight-badge">40% Weight</span>
                    </div>
                    <div>
                        <strong>Semantic Comparison:</strong><br>
                        • Project domains vs job responsibilities<br>
                        • Publication topics vs required expertise<br>
                        • Technology stack overlap<br><br>
                        <strong>Example:</strong><br>
                        Job needs: "Machine Learning for Healthcare"<br>
                        Candidate project: "AI-based Medical Diagnosis System"<br>
                        Semantic Score: 0.92 (excellent match)
                    </div>
                </div>

                <div class="feature-card skills-card">
                    <div class="feature-title">
                        <span>💻</span>
                        Skills Match
                        <span class="weight-badge">10% Weight</span>
                    </div>
                    <div>
                        <strong>Semantic Comparison:</strong><br>
                        • Technical skills vs job requirements<br>
                        • Programming languages, frameworks, tools<br>
                        • Skill level proficiency matching<br><br>
                        <strong>Example:</strong><br>
                        Job requires: "Python, TensorFlow, Deep Learning"<br>
                        Candidate has: "Python, PyTorch, Neural Networks"<br>
                        Semantic Score: 0.78 (good overlap)
                    </div>
                </div>

                <div class="feature-card experience-card">
                    <div class="feature-title">
                        <span>💼</span>
                        Experience Level
                        <span class="weight-badge">Implicit</span>
                    </div>
                    <div>
                        <strong>Semantic Comparison:</strong><br>
                        • Years of experience vs job level<br>
                        • Industry experience relevance<br>
                        • Role progression and leadership<br><br>
                        <strong>Example:</strong><br>
                        Job requires: "5+ years in data science"<br>
                        Candidate has: "6 years as ML Engineer"<br>
                        Semantic Score: 0.88 (strong match)
                    </div>
                </div>
            </div>

            <div class="workflow-section">
                <div class="workflow-title">🔄 Your Complete Ranking Pipeline</div>
                
                <div class="workflow-steps">
                    <div class="workflow-step">
                        <div class="step-number">1</div>
                        <div class="step-title">Semantic Scoring</div>
                        <div>
                            Compare candidate features with job requirements using NLP/embeddings<br>
                            Output: Individual scores (0-1) for each feature
                        </div>
                    </div>
                    
                    <div class="workflow-step">
                        <div class="step-number">2</div>
                        <div class="step-title">Weighted Combination</div>
                        <div>
                            Apply business weights:<br>
                            50% Education + 40% Projects + 10% Skills<br>
                            Output: Overall semantic score
                        </div>
                    </div>
                    
                    <div class="workflow-step">
                        <div class="step-number">3</div>
                        <div class="step-title">Feature Engineering</div>
                        <div>
                            Create training dataset with:<br>
                            • Individual semantic scores<br>
                            • Combined weighted score<br>
                            • Target ranking labels
                        </div>
                    </div>
                    
                    <div class="workflow-step">
                        <div class="step-number">4</div>
                        <div class="step-title">XGBoost Training</div>
                        <div>
                            Train ranking model to learn complex patterns beyond simple weighted sum<br>
                            Output: Sophisticated ranking function
                        </div>
                    </div>
                </div>
            </div>

            <div style="background: rgba(255,255,255,0.1); border-radius: 20px; padding: 30px; margin: 30px 0;">
                <h3 style="color: #ffd700; margin-bottom: 20px; text-align: center;">📊 Sample Data Structure</h3>
                
                <div class="results-table">
                    <div class="table-header">Your Training Dataset Structure</div>
                    <div class="table-row">
                        <div class="table-cell"><strong>Candidate</strong></div>
                        <div class="table-cell"><strong>Education Score</strong></div>
                        <div class="table-cell"><strong>Projects Score</strong></div>
                        <div class="table-cell"><strong>Skills Score</strong></div>
                        <div class="table-cell"><strong>Weighted Score</strong></div>
                        <div class="table-cell"><strong>Rank Label</strong></div>
                    </div>
                    <div class="table-row">
                        <div class="table-cell">Alice Johnson</div>
                        <div class="table-cell">0.92</div>
                        <div class="table-cell">0.85</div>
                        <div class="table-cell">0.78</div>
                        <div class="table-cell">0.867</div>
                        <div class="table-cell">1 (Best)</div>
                    </div>
                    <div class="table-row">
                        <div class="table-cell">Bob Smith</div>
                        <div class="table-cell">0.75</div>
                        <div class="table-cell">0.90</div>
                        <div class="table-cell">0.82</div>
                        <div class="table-cell">0.815</div>
                        <div class="table-cell">2</div>
                    </div>
                    <div class="table-row">
                        <div class="table-cell">Carol Davis</div>
                        <div class="table-cell">0.88</div>
                        <div class="table-cell">0.65</div>
                        <div class="table-cell">0.90</div>
                        <div class="table-cell">0.770</div>
                        <div class="table-cell">3</div>
                    </div>
                </div>
                
                <div style="text-align: center; margin-top: 20px; font-style: italic;">
                    Weighted Score = 0.5×Education + 0.4×Projects + 0.1×Skills
                </div>
            </div>
        </div>

        <!-- Implementation -->
        <div id="implementation" class="content-section">
            <div class="code-example">
                <div class="code-title">🎯 Your Complete XGBoost Ranking Implementation</div>
                <div class="code-line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div>
                <div class="code-line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div>
                <div class="code-line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
                <div class="code-line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div>
                <div class="code-line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> ndcg_score</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 1: Prepare your semantic scoring data</span></div>
                <div class="code-line">candidate_data = {</div>
                <div class="code-line">    <span class="string">'candidate_id'</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</div>
                <div class="code-line">    <span class="string">'education_score'</span>: [<span class="number">0.92</span>, <span class="number">0.75</span>, <span class="number">0.88</span>, <span class="number">0.65</span>, <span class="number">0.78</span>],</div>
                <div class="code-line">    <span class="string">'projects_score'</span>: [<span class="number">0.85</span>, <span class="number">0.90</span>, <span class="number">0.65</span>, <span class="number">0.80</span>, <span class="number">0.72</span>],</div>
                <div class="code-line">    <span class="string">'skills_score'</span>: [<span class="number">0.78</span>, <span class="number">0.82</span>, <span class="number">0.90</span>, <span class="number">0.70</span>, <span class="number">0.85</span>],</div>
                <div class="code-line">    <span class="string">'publications_score'</span>: [<span class="number">0.80</span>, <span class="number">0.60</span>, <span class="number">0.95</span>, <span class="number">0.40</span>, <span class="number">0.55</span>],</div>
                <div class="code-line">    <span class="string">'experience_years'</span>: [<span class="number">6</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">5</span>],</div>
                <div class="code-line">    <span class="string">'rank_label'</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># 1 = best candidate</span></div>
                <div class="code-line">}</div>
                <div class="code-line"></div>
                <div class="code-line">df = pd.DataFrame(candidate_data)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 2: Calculate your weighted composite score</span></div>
                <div class="code-line">df[<span class="string">'weighted_score'</span>] = (</div>
                <div class="code-line">    <span class="number">0.5</span> * df[<span class="string">'education_score'</span>] +     <span class="comment"># 50% weight</span></div>
                <div class="code-line">    <span class="number">0.4</span> * df[<span class="string">'projects_score'</span>] +     <span class="comment"># 40% weight</span></div>
                <div class="code-line">    <span class="number">0.1</span> * df[<span class="string">'skills_score'</span>]         <span class="comment"># 10% weight</span></div>
                <div class="code-line">)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 3: Prepare features for XGBoost</span></div>
                <div class="code-line">features = [<span class="string">'education_score'</span>, <span class="string">'projects_score'</span>, <span class="string">'skills_score'</span>, </div>
                <div class="code-line">           <span class="string">'publications_score'</span>, <span class="string">'experience_years'</span>, <span class="string">'weighted_score'</span>]</div>
                <div class="code-line"></div>
                <div class="code-line">X = df[features]</div>
                <div class="code-line">y = df[<span class="string">'rank_label'</span>]  <span class="comment"># Target rankings</span></div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 4: Create XGBoost ranking model</span></div>
                <div class="code-line">xgb_ranker = xgb.XGBRanker(</div>
                <div class="code-line">    <span class="comment"># Boosting parameters</span></div>
                <div class="code-line">    n_estimators=<span class="number">100</span>,        <span class="comment"># Number of sequential trees</span></div>
                <div class="code-line">    learning_rate=<span class="number">0.1</span>,       <span class="comment"># Shrinkage (boosting control)</span></div>
                <div class="code-line">    max_depth=<span class="number">6</span>,            <span class="comment"># Tree depth</span></div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Bagging parameters (the hybrid part!)</span></div>
                <div class="code-line">    subsample=<span class="number">0.8</span>,          <span class="comment"># Use 80% of rows per tree</span></div>
                <div class="code-line">    colsample_bytree=<span class="number">0.8</span>,   <span class="comment"># Use 80% of features per tree</span></div>
                <div class="code-line">    colsample_bylevel=<span class="number">0.8</span>,  <span class="comment"># Feature sampling per level</span></div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Regularization (prevents overfitting)</span></div>
                <div class="code-line">    reg_alpha=<span class="number">0.1</span>,          <span class="comment"># L1 regularization</span></div>
                <div class="code-line">    reg_lambda=<span class="number">0.1</span>,         <span class="comment"># L2 regularization</span></div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Ranking specific</span></div>
                <div class="code-line">    objective=<span class="string">'rank:pairwise'</span>,  <span class="comment"># Ranking objective</span></div>
                <div class="code-line">    random_state=<span class="number">42</span></div>
                <div class="code-line">)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 5: Train the model</span></div>
                <div class="code-line"><span class="comment"># For ranking, we need group information</span></div>
                <div class="code-line">group_sizes = [len(df)]  <span class="comment"># All candidates in one ranking group</span></div>
                <div class="code-line"></div>
                <div class="code-line">xgb_ranker.fit(</div>
                <div class="code-line">    X, y, </div>
                <div class="code-line">    group=group_sizes,  <span class="comment"># Required for ranking</span></div>
                <div class="code-line">    verbose=<span class="keyword">True</span></div>
                <div class="code-line">)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Step 6: Make predictions and rank</span></div>
                <div class="code-line">ranking_scores = xgb_ranker.predict(X)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Get final rankings</span></div>
                <div class="code-line">df[<span class="string">'xgb_score'</span>] = ranking_scores</div>
                <div class="code-line">df[<span class="string">'xgb_rank'</span>] = df[<span class="string">'xgb_score'</span>].rank(ascending=<span class="keyword">False</span>)</div>
                <div class="code-line"></div>
                <div class="code-line">print(<span class="string">"Final Rankings:"</span>)</div>
                <div class="code-line">print(df[[<span class="string">'candidate_id'</span>, <span class="string">'weighted_score'</span>, <span class="string">'xgb_score'</span>, <span class="string">'xgb_rank'</span>]].sort_values(<span class="string">'xgb_rank'</span>))</div>
            </div>

            <div class="code-example">
                <div class="code-title">🔍 Feature Importance Analysis</div>
                <div class="code-line"><span class="comment"># Analyze what XGBoost learned</span></div>
                <div class="code-line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Get feature importance</span></div>
                <div class="code-line">importance = xgb_ranker.feature_importances_</div>
                <div class="code-line">feature_names = X.columns</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Create importance dataframe</span></div>
                <div class="code-line">importance_df = pd.DataFrame({</div>
                <div class="code-line">    <span class="string">'feature'</span>: feature_names,</div>
                <div class="code-line">    <span class="string">'importance'</span>: importance</div>
                <div class="code-line">}).sort_values(<span class="string">'importance'</span>, ascending=<span class="keyword">False</span>)</div>
                <div class="code-line"></div>
                <div class="code-line">print(<span class="string">"XGBoost learned these feature importances:"</span>)</div>
                <div class="code-line">print(importance_df)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Plot feature importance</span></div>
                <div class="code-line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</div>
                <div class="code-line">plt.barh(importance_df[<span class="string">'feature'</span>], importance_df[<span class="string">'importance'</span>])</div>
                <div class="code-line">plt.title(<span class="string">'XGBoost Feature Importance for Ranking'</span>)</div>
                <div class="code-line">plt.xlabel(<span class="string">'Importance Score'</span>)</div>
                <div class="code-line">plt.show()</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Compare with your manual weights</span></div>
                <div class="code-line">manual_weights = {</div>
                <div class="code-line">    <span class="string">'education_score'</span>: <span class="number">0.5</span>,</div>
                <div class="code-line">    <span class="string">'projects_score'</span>: <span class="number">0.4</span>,</div>
                <div class="code-line">    <span class="string">'skills_score'</span>: <span class="number">0.1</span></div>
                <div class="code-line">}</div>
                <div class="code-line"></div>
                <div class="code-line">print(<span class="string">"Your manual weights vs XGBoost learned weights:"</span>)</div>
                <div class="code-line"><span class="keyword">for</span> feature <span class="keyword">in</span> manual_weights:</div>
                <div class="code-line">    manual_w = manual_weights[feature]</div>
                <div class="code-line">    xgb_w = importance_df[importance_df[<span class="string">'feature'</span>] == feature][<span class="string">'importance'</span>].iloc[<span class="number">0</span>]</div>
                <div class="code-line">    print(<span class="string">f"{feature}: Manual={manual_w:.1f}, XGBoost={xgb_w:.3f}"</span>)</div>
            </div>

            <div class="code-example">
                <div class="code-title">📊 Advanced: Semantic Score Calculation</div>
                <div class="code-line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</div>
                <div class="code-line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Load pre-trained sentence transformer</span></div>
                <div class="code-line">model = SentenceTransformer(<span class="string">'all-MiniLM-L6-v2'</span>)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="keyword">def</span> calculate_semantic_score(candidate_text, job_requirement_text):</div>
                <div class="code-line">    <span class="string">"""Calculate semantic similarity between candidate and job requirement"""</span></div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Convert to embeddings</span></div>
                <div class="code-line">    candidate_embedding = model.encode([candidate_text])</div>
                <div class="code-line">    job_embedding = model.encode([job_requirement_text])</div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Calculate cosine similarity</span></div>
                <div class="code-line">    similarity = cosine_similarity(candidate_embedding, job_embedding)[<span class="number">0</span>][<span class="number">0</span>]</div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="keyword">return</span> max(<span class="number">0</span>, similarity)  <span class="comment"># Ensure non-negative</span></div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Example usage for your dataset</span></div>
                <div class="code-line">job_requirements = {</div>
                <div class="code-line">    <span class="string">'education'</span>: <span class="string">"Master's degree in Computer Science or related field"</span>,</div>
                <div class="code-line">    <span class="string">'projects'</span>: <span class="string">"Experience with machine learning projects, data science applications"</span>,</div>
                <div class="code-line">    <span class="string">'skills'</span>: <span class="string">"Python, TensorFlow, deep learning, statistical analysis"</span>,</div>
                <div class="code-line">    <span class="string">'publications'</span>: <span class="string">"Research publications in AI/ML, conference papers"</span></div>
                <div class="code-line">}</div>
                <div class="code-line"></div>
                <div class="code-line">candidate_profile = {</div>
                <div class="code-line">    <span class="string">'education'</span>: <span class="string">"MS in Software Engineering, focus on AI"</span>,</div>
                <div class="code-line">    <span class="string">'projects'</span>: <span class="string">"Built recommendation system, NLP chatbot, computer vision app"</span>,</div>
                <div class="code-line">    <span class="string">'skills'</span>: <span class="string">"Python, PyTorch, neural networks, data analysis"</span>,</div>
                <div class="code-line">    <span class="string">'publications'</span>: <span class="string">"2 papers on deep learning for healthcare"</span></div>
                <div class="code-line">}</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Calculate semantic scores</span></div>
                <div class="code-line">semantic_scores = {}</div>
                <div class="code-line"><span class="keyword">for</span> feature <span class="keyword">in</span> job_requirements:</div>
                <div class="code-line">    score = calculate_semantic_score(</div>
                <div class="code-line">        candidate_profile[feature], </div>
                <div class="code-line">        job_requirements[feature]</div>
                <div class="code-line">    )</div>
                <div class="code-line">    semantic_scores[feature] = score</div>
                <div class="code-line">    print(<span class="string">f"{feature}_score: {score:.3f}"</span>)</div>
            </div>
        </div>

        <!-- Optimization -->
        <div id="optimization" class="content-section">
            <div class="concept-card">
                <div class="card-title">
                    <span>🎯</span>
                    Why XGBoost Works So Well for Your Use Case
                </div>
                <div style="font-size: 1.1em; line-height: 1.8;">
                    <p style="margin-bottom: 20px;">
                        <strong>Your ranking problem is PERFECT for XGBoost because:</strong>
                    </p>
                    
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 25px 0;">
                        <div style="background: rgba(78,205,196,0.2); padding: 20px; border-radius: 12px;">
                            <strong>🎯 Complex Patterns</strong><br>
                            XGBoost can learn that sometimes high projects score can compensate for lower education score - 
                            patterns your simple weighted sum can't capture!
                        </div>
                        
                        <div style="background: rgba(255,215,0,0.2); padding: 20px; border-radius: 12px;">
                            <strong>📊 Non-Linear Relationships</strong><br>
                            Maybe education matters more for junior roles but projects matter more for senior roles. 
                            XGBoost learns these conditional relationships!
                        </div>
                        
                        <div style="background: rgba(255,107,107,0.2); padding: 20px; border-radius: 12px;">
                            <strong>⚖️ Feature Interactions</strong><br>
                            XGBoost discovers interactions like "High publications + Low experience = Research role fit" 
                            or "High projects + Medium education = Industry role fit"
                        </div>
                    </div>
                </div>
            </div>

            <div class="code-example">
                <div class="code-title">🔧 Hyperparameter Tuning for Your Ranking Model</div>
                <div class="code-line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div>
                <div class="code-line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Define parameter grid for your ranking problem</span></div>
                <div class="code-line">param_grid = {</div>
                <div class="code-line">    <span class="comment"># Boosting parameters</span></div>
                <div class="code-line">    <span class="string">'n_estimators'</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>],    <span class="comment"># More trees = more sequential learning</span></div>
                <div class="code-line">    <span class="string">'learning_rate'</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],  <span class="comment"># How much each tree contributes</span></div>
                <div class="code-line">    <span class="string">'max_depth'</span>: [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>],         <span class="comment"># Tree complexity</span></div>
                <div class="code-line">    </div>
                <div class="code-line">    <span class="comment"># Bagging parameters (the hybrid magic!)</span></div>
                <div class="code-line">    <span class="string">'subsample'</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>],      <span class="comment"># Row sampling like bagging</span></div>
                <div class="code-line">    <span class="string">'colsample_bytree'</span>: [<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">1.0</span>]  <span class="comment"># Feature sampling like Random Forest</span></div>
                <div class="code-line">}</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># For ranking, we'll use a regression approach</span></div>
                <div class="code-line">xgb_reg = xgb.XGBRegressor(</div>
                <div class="code-line">    objective=<span class="string">'reg:squarederror'</span>,</div>
                <div class="code-line">    random_state=<span class="number">42</span></div>
                <div class="code-line">)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Grid search to find best parameters</span></div>
                <div class="code-line">grid_search = GridSearchCV(</div>
                <div class="code-line">    xgb_reg, </div>
                <div class="code-line">    param_grid, </div>
                <div class="code-line">    cv=<span class="number">5</span>,  <span class="comment"># 5-fold cross-validation</span></div>
                <div class="code-line">    scoring=<span class="string">'neg_mean_squared_error'</span>,  <span class="comment"># Good for ranking</span></div>
                <div class="code-line">    n_jobs=-<span class="number">1</span>  <span class="comment"># Use all cores</span></div>
                <div class="code-line">)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Train to find optimal hyperparameters</span></div>
                <div class="code-line">grid_search.fit(X, y)</div>
                <div class="code-line"></div>
                <div class="code-line">print(<span class="string">f"Best parameters: {grid_search.best_params_}"</span>)</div>
                <div class="code-line">print(<span class="string">f"Best score: {grid_search.best_score_:.4f}"</span>)</div>
                <div class="code-line"></div>
                <div class="code-line"><span class="comment"># Get the best model</span></div>
                <div class="code-line">best_xgb_model = grid_search.best_estimator_</div>
            </div>

            <div style="background: rgba(255,255,255,0.1); border-radius: 20px; padding: 30px; margin: 30px 0;">
                <h3 style="color: #ffd700; text-align: center; margin-bottom: 20px;">🧠 What XGBoost Learns Beyond Your Weights</h3>
                
                <div style="font-size: 1.1em; line-height: 1.7;">
                    <p style="margin-bottom: 20px;">
                        <strong>Your manual approach:</strong> Simple weighted sum (50% education + 40% projects + 10% skills)
                    </p>
                    
                    <p style="margin-bottom: 20px;">
                        <strong>What XGBoost discovers:</strong>
                    </p>
                    
                    <div style="background: rgba(255,215,0,0.2); padding: 20px; border-radius: 12px; margin: 20px 0;">
                        <strong>🔍 Conditional Rules XGBoost Might Learn:</strong><br><br>
                        • "If education_score > 0.8 AND projects_score < 0.6 → Reduce overall rank (academic but no practical experience)"<br><br>
                        • "If projects_score > 0.9 AND education_score < 0.7 → Still rank high (strong practical skills compensate)"<br><br>
                        • "If publications_score > 0.8 AND experience < 3 years → Research-focused candidate (different weighting)"<br><br>
                        • "If skills_score > 0.9 → Boost rank significantly (rare technical expert)"
                    </div>
                    
                    <p style="margin-bottom: 20px;">
                        <strong>Your weighted sum can't capture these nuances!</strong> XGBoost builds decision trees that learn:
                    </p>
                    
                    <ul style="margin-left: 20px; margin-bottom: 20px;">
                        <li>When education matters more vs when projects matter more</li>
                        <li>How different combinations of scores affect ranking</li>
                        <li>Non-linear relationships between features</li>
                        <li>Interactions between multiple features simultaneously</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Final Summary -->
        <div style="background: linear-gradient(45deg, #667eea, #764ba2); border-radius: 20px; padding: 40px; margin: 40px 0; text-align: center;">
            <h2 style="margin-bottom: 25px;">🎓 Your XGBoost Ranking Model: The Complete Picture</h2>
            <div style="font-size: 1.2em; line-height: 1.8; max-width: 900px; margin: 0 auto;">
                <p style="margin-bottom: 20px;">
                    <strong>🤖 XGBoost Nature:</strong> Primarily boosting (sequential error correction) enhanced with bagging techniques (row/column sampling)
                </p>
                <p style="margin-bottom: 20px;">
                    <strong>🎯 Your Innovation:</strong> You created semantic scores using NLP, applied business weights, then let XGBoost learn the complex patterns your weighted sum couldn't capture
                </p>
                <p style="margin-bottom: 20px;">
                    <strong>🚀 The Result:</strong> A sophisticated ranking system that combines domain expertise (your weights) with machine learning pattern discovery (XGBoost's trees)
                </p>
                <p>
                    <strong>💡 Why It Works:</strong> XGBoost learns when education vs projects vs skills matter most, discovers feature interactions, and creates a ranking function far more nuanced than any manual weighting! 🏆
                </p>
            </div>
        </div>
    </div>

    <script>
        function showSection(sectionId) {
            // Hide all sections
            const sections = document.querySelectorAll('.content-section');
            sections.forEach(section => {
                section.classList.remove('active');
            });
            
            // Remove active from all tabs  
            const tabs = document.querySelectorAll('.tab-btn');
            tabs.forEach(tab => {
                tab.classList.remove('active');
            });
            
            // Show target section
            const targetSection = document.getElementById(sectionId);
            if (targetSection) {
                targetSection.classList.add('active');
            }
            
            // Activate current tab
            if (event && event.target) {
                event.target.classList.add('active');
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            console.log('XGBoost ranking guide loaded successfully!');
        });
    </script>
</body>
</html>
